{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lVYnKo5XWfKz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1mNQGvmZWSQW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.callbacks import LambdaCallback, ModelCheckpoint\n",
        "from keras.layers import LSTM, Dense, Activation\n",
        "import itertools\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rzYmLKgAWbPn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 2
            }
          ],
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "48cb7a82-5559-49f7-c25b-ca0580684ee1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520559583628,
          "user_tz": 480,
          "elapsed": 7617,
          "user": {
            "displayName": "Qingzhuo Aw Young",
            "photoUrl": "//lh5.googleusercontent.com/-KgAiD_zBKV8/AAAAAAAAAAI/AAAAAAAAEKY/z2XK7TaGpXM/s50-c-k-no/photo.jpg",
            "userId": "100798512376314782861"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "for fn, c in uploaded.items():\n",
        "  with open(fn, 'wb') as f:\n",
        "    f.write(c)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-060d7038-53c7-4c41-a3c2-3cae36735b9b\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-060d7038-53c7-4c41-a3c2-3cae36735b9b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "User uploaded file \"shakespeare.txt\" with length 100643 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nPXKRPmUW2NV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "14U-VI9QWSQa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with open('shakespeare.txt') as f:\n",
        "  lines = [line.strip(' ').lower() for line in f] #.strip('\\n ,.:')\n",
        "sonnets = []\n",
        "ln_start = 0\n",
        "ln_end = 0\n",
        "for ln, content in enumerate(lines):\n",
        "    if content[:-1].isdigit():\n",
        "        ln_start = ln + 1\n",
        "    elif not content[:-1]:\n",
        "        if ln - 1 == ln_end:\n",
        "            sonnets.append(lines[ln_start:ln_end + 1])\n",
        "    elif ln + 1 == len(lines):\n",
        "        sonnets.append(lines[ln_start:ln_end + 1])\n",
        "    else:\n",
        "        ln_end = ln"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IEvss39nWSQd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "chars = sorted(set([c for s in sonnets for l in s for c in l]))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fQ1YSw10WSQi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e429dcbd-545b-4201-afce-fe29b8f1605f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520565552217,
          "user_tz": 480,
          "elapsed": 330,
          "user": {
            "displayName": "Qingzhuo Aw Young",
            "photoUrl": "//lh5.googleusercontent.com/-KgAiD_zBKV8/AAAAAAAAAAI/AAAAAAAAEKY/z2XK7TaGpXM/s50-c-k-no/photo.jpg",
            "userId": "100798512376314782861"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "maxlen = 40\n",
        "step = 1\n",
        "sentences = []\n",
        "next_chars = []\n",
        "text = ''.join([c for s in sonnets for l in s for c in l])\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 93587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ado2HCwKYiy-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "collapsed": true,
        "outputId": "b3f95b09-fc52-4456-cc89-7f57a8dd4d13",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520565553207,
          "user_tz": 480,
          "elapsed": 287,
          "user": {
            "displayName": "Qingzhuo Aw Young",
            "photoUrl": "//lh5.googleusercontent.com/-KgAiD_zBKV8/AAAAAAAAAAI/AAAAAAAAEKY/z2XK7TaGpXM/s50-c-k-no/photo.jpg",
            "userId": "100798512376314782861"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "chars"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "metadata": {
        "id": "3ceQHFWnWSQq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U_9fsGJrWSQt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='ADAM')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "014RTHGoWSQ1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "  \n",
        "def on_epoch_end(epoch, logs):\n",
        "    import random\n",
        "    import sys\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w2zbOKg2WSQw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 82
            },
            {
              "item_id": 141
            },
            {
              "item_id": 196
            },
            {
              "item_id": 256
            },
            {
              "item_id": 311
            },
            {
              "item_id": 365
            },
            {
              "item_id": 418
            },
            {
              "item_id": 471
            },
            {
              "item_id": 524
            },
            {
              "item_id": 577
            },
            {
              "item_id": 631
            },
            {
              "item_id": 684
            },
            {
              "item_id": 737
            },
            {
              "item_id": 790
            },
            {
              "item_id": 843
            },
            {
              "item_id": 895
            },
            {
              "item_id": 948
            },
            {
              "item_id": 1000
            },
            {
              "item_id": 1053
            },
            {
              "item_id": 1106
            },
            {
              "item_id": 1159
            },
            {
              "item_id": 1212
            },
            {
              "item_id": 1265
            },
            {
              "item_id": 1318
            },
            {
              "item_id": 1371
            },
            {
              "item_id": 1424
            },
            {
              "item_id": 1477
            },
            {
              "item_id": 1530
            },
            {
              "item_id": 1584
            },
            {
              "item_id": 1637
            },
            {
              "item_id": 1690
            },
            {
              "item_id": 1743
            },
            {
              "item_id": 1796
            },
            {
              "item_id": 1849
            },
            {
              "item_id": 1895
            },
            {
              "item_id": 1953
            },
            {
              "item_id": 2008
            },
            {
              "item_id": 2062
            },
            {
              "item_id": 2108
            },
            {
              "item_id": 2166
            },
            {
              "item_id": 2221
            },
            {
              "item_id": 2275
            },
            {
              "item_id": 2328
            },
            {
              "item_id": 2381
            },
            {
              "item_id": 2434
            },
            {
              "item_id": 2487
            },
            {
              "item_id": 2540
            },
            {
              "item_id": 2593
            },
            {
              "item_id": 2646
            },
            {
              "item_id": 2699
            },
            {
              "item_id": 2744
            },
            {
              "item_id": 2802
            },
            {
              "item_id": 2850
            },
            {
              "item_id": 2908
            },
            {
              "item_id": 2963
            },
            {
              "item_id": 3017
            },
            {
              "item_id": 3063
            },
            {
              "item_id": 3122
            },
            {
              "item_id": 3177
            },
            {
              "item_id": 3231
            },
            {
              "item_id": 3285
            },
            {
              "item_id": 3331
            },
            {
              "item_id": 3382
            },
            {
              "item_id": 3441
            },
            {
              "item_id": 3496
            },
            {
              "item_id": 3550
            },
            {
              "item_id": 3603
            },
            {
              "item_id": 3657
            },
            {
              "item_id": 3710
            },
            {
              "item_id": 3764
            },
            {
              "item_id": 3817
            },
            {
              "item_id": 3863
            },
            {
              "item_id": 3921
            },
            {
              "item_id": 3976
            },
            {
              "item_id": 4030
            },
            {
              "item_id": 4076
            },
            {
              "item_id": 4135
            },
            {
              "item_id": 4189
            },
            {
              "item_id": 4235
            },
            {
              "item_id": 4293
            },
            {
              "item_id": 4348
            },
            {
              "item_id": 4401
            },
            {
              "item_id": 4454
            },
            {
              "item_id": 4507
            },
            {
              "item_id": 4560
            },
            {
              "item_id": 4606
            },
            {
              "item_id": 4663
            },
            {
              "item_id": 4717
            },
            {
              "item_id": 4771
            },
            {
              "item_id": 4824
            },
            {
              "item_id": 4877
            },
            {
              "item_id": 4930
            },
            {
              "item_id": 4983
            },
            {
              "item_id": 5028
            },
            {
              "item_id": 5085
            },
            {
              "item_id": 5132
            },
            {
              "item_id": 5190
            },
            {
              "item_id": 5244
            },
            {
              "item_id": 5297
            },
            {
              "item_id": 5343
            },
            {
              "item_id": 5400
            },
            {
              "item_id": 5455
            },
            {
              "item_id": 5508
            },
            {
              "item_id": 5561
            },
            {
              "item_id": 5615
            },
            {
              "item_id": 5668
            },
            {
              "item_id": 5764
            },
            {
              "item_id": 5816
            },
            {
              "item_id": 5868
            },
            {
              "item_id": 5920
            },
            {
              "item_id": 6028
            },
            {
              "item_id": 6134
            },
            {
              "item_id": 6186
            },
            {
              "item_id": 6238
            },
            {
              "item_id": 6275
            },
            {
              "item_id": 6322
            },
            {
              "item_id": 6373
            },
            {
              "item_id": 6422
            },
            {
              "item_id": 6467
            },
            {
              "item_id": 6509
            },
            {
              "item_id": 6566
            },
            {
              "item_id": 6621
            },
            {
              "item_id": 6674
            },
            {
              "item_id": 6725
            },
            {
              "item_id": 6761
            },
            {
              "item_id": 6774
            },
            {
              "item_id": 6802
            },
            {
              "item_id": 6851
            },
            {
              "item_id": 6868
            },
            {
              "item_id": 6890
            },
            {
              "item_id": 6896
            },
            {
              "item_id": 6929
            },
            {
              "item_id": 6980
            },
            {
              "item_id": 7034
            },
            {
              "item_id": 7081
            },
            {
              "item_id": 7120
            },
            {
              "item_id": 7174
            },
            {
              "item_id": 7228
            },
            {
              "item_id": 7264
            },
            {
              "item_id": 7296
            },
            {
              "item_id": 7356
            },
            {
              "item_id": 7357
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 10910
        },
        "outputId": "c9f53d76-8e3e-411f-86a8-e3cb74832cb7",
        "executionInfo": {
          "status": "error",
          "timestamp": 1520576723631,
          "user_tz": 480,
          "elapsed": 7363001,
          "user": {
            "displayName": "Qingzhuo Aw Young",
            "photoUrl": "//lh5.googleusercontent.com/-KgAiD_zBKV8/AAAAAAAAAAI/AAAAAAAAEKY/z2XK7TaGpXM/s50-c-k-no/photo.jpg",
            "userId": "100798512376314782861"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=600,\n",
        "          callbacks=[checkpoint])"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "93587/93587 [==============================] - 52s 561us/step - loss: 0.2480\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.24800, saving model to weights-improvement-01-0.2480.hdf5\n",
            "Epoch 2/600\n",
            "18816/93587 [=====>........................] - ETA: 41s - loss: 0.1550"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 560us/step - loss: 0.1709\n",
            "\n",
            "Epoch 00002: loss improved from 0.24800 to 0.17092, saving model to weights-improvement-02-0.1709.hdf5\n",
            "Epoch 3/600\n",
            "28672/93587 [========>.....................] - ETA: 36s - loss: 0.1252"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 558us/step - loss: 0.1545\n",
            "\n",
            "Epoch 00003: loss improved from 0.17092 to 0.15449, saving model to weights-improvement-03-0.1545.hdf5\n",
            "Epoch 4/600\n",
            "31232/93587 [=========>....................] - ETA: 34s - loss: 0.1588"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 558us/step - loss: 0.2089\n",
            "\n",
            "Epoch 00004: loss did not improve\n",
            "Epoch 5/600\n",
            "43392/93587 [============>.................] - ETA: 27s - loss: 0.2196"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.2449\n",
            "\n",
            "Epoch 00005: loss did not improve\n",
            "Epoch 6/600\n",
            "47744/93587 [==============>...............] - ETA: 25s - loss: 0.2090"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.2293\n",
            "\n",
            "Epoch 00006: loss did not improve\n",
            "Epoch 7/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.1752"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.2031\n",
            "\n",
            "Epoch 00007: loss did not improve\n",
            "Epoch 8/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1759"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.1994\n",
            "\n",
            "Epoch 00008: loss did not improve\n",
            "Epoch 9/600\n",
            "50048/93587 [===============>..............] - ETA: 24s - loss: 0.1943"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.2148\n",
            "\n",
            "Epoch 00009: loss did not improve\n",
            "Epoch 10/600\n",
            "49920/93587 [===============>..............] - ETA: 24s - loss: 0.1774"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 559us/step - loss: 0.2011\n",
            "\n",
            "Epoch 00010: loss did not improve\n",
            "Epoch 11/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1839"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 53s 564us/step - loss: 0.2056\n",
            "\n",
            "Epoch 00011: loss did not improve\n",
            "Epoch 12/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1713"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 53s 562us/step - loss: 0.1941\n",
            "\n",
            "Epoch 00012: loss did not improve\n",
            "Epoch 13/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1678"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 557us/step - loss: 0.1991\n",
            "\n",
            "Epoch 00013: loss did not improve\n",
            "Epoch 14/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1809"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.2012\n",
            "\n",
            "Epoch 00014: loss did not improve\n",
            "Epoch 15/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1600"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.1842\n",
            "\n",
            "Epoch 00015: loss did not improve\n",
            "Epoch 16/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1611"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.1896\n",
            "\n",
            "Epoch 00016: loss did not improve\n",
            "Epoch 17/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1697"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.1921\n",
            "\n",
            "Epoch 00017: loss did not improve\n",
            "Epoch 18/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1660"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.1845\n",
            "\n",
            "Epoch 00018: loss did not improve\n",
            "Epoch 19/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1652"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.1814\n",
            "\n",
            "Epoch 00019: loss did not improve\n",
            "Epoch 20/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1628"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 555us/step - loss: 0.1852\n",
            "\n",
            "Epoch 00020: loss did not improve\n",
            "Epoch 21/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1549"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 557us/step - loss: 0.1761\n",
            "\n",
            "Epoch 00021: loss did not improve\n",
            "Epoch 22/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1506"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1690\n",
            "\n",
            "Epoch 00022: loss did not improve\n",
            "Epoch 23/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1487"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1759\n",
            "\n",
            "Epoch 00023: loss did not improve\n",
            "Epoch 24/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1771"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1915\n",
            "\n",
            "Epoch 00024: loss did not improve\n",
            "Epoch 25/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1352"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1581\n",
            "\n",
            "Epoch 00025: loss did not improve\n",
            "Epoch 26/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1518"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 555us/step - loss: 0.1789\n",
            "\n",
            "Epoch 00026: loss did not improve\n",
            "Epoch 27/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1804"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1936\n",
            "\n",
            "Epoch 00027: loss did not improve\n",
            "Epoch 28/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1382"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1563\n",
            "\n",
            "Epoch 00028: loss did not improve\n",
            "Epoch 29/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1332"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 558us/step - loss: 0.1575\n",
            "\n",
            "Epoch 00029: loss did not improve\n",
            "Epoch 30/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1488"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 557us/step - loss: 0.1666\n",
            "\n",
            "Epoch 00030: loss did not improve\n",
            "Epoch 31/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1502"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1628\n",
            "\n",
            "Epoch 00031: loss did not improve\n",
            "Epoch 32/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1371"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 557us/step - loss: 0.1583\n",
            "\n",
            "Epoch 00032: loss did not improve\n",
            "Epoch 33/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1442"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1707\n",
            "\n",
            "Epoch 00033: loss did not improve\n",
            "Epoch 34/600\n",
            "49664/93587 [==============>...............] - ETA: 24s - loss: 0.1470"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1624\n",
            "\n",
            "Epoch 00034: loss did not improve\n",
            "Epoch 35/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1295"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 558us/step - loss: 0.1495\n",
            "\n",
            "Epoch 00035: loss improved from 0.15449 to 0.14946, saving model to weights-improvement-35-0.1495.hdf5\n",
            "Epoch 36/600\n",
            "36736/93587 [==========>...................] - ETA: 31s - loss: 0.1381"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 557us/step - loss: 0.1615\n",
            "\n",
            "Epoch 00036: loss did not improve\n",
            "Epoch 37/600\n",
            "45056/93587 [=============>................] - ETA: 27s - loss: 0.1444"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 558us/step - loss: 0.1615\n",
            "\n",
            "Epoch 00037: loss did not improve\n",
            "Epoch 38/600\n",
            "48128/93587 [==============>...............] - ETA: 25s - loss: 0.1336"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 558us/step - loss: 0.1500\n",
            "\n",
            "Epoch 00038: loss did not improve\n",
            "Epoch 39/600\n",
            "49152/93587 [==============>...............] - ETA: 24s - loss: 0.1183"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 559us/step - loss: 0.1413\n",
            "\n",
            "Epoch 00039: loss improved from 0.14946 to 0.14134, saving model to weights-improvement-39-0.1413.hdf5\n",
            "Epoch 40/600\n",
            "36608/93587 [==========>...................] - ETA: 31s - loss: 0.1395"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 559us/step - loss: 0.1657\n",
            "\n",
            "Epoch 00040: loss did not improve\n",
            "Epoch 41/600\n",
            "45056/93587 [=============>................] - ETA: 27s - loss: 0.1384"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 559us/step - loss: 0.1603\n",
            "\n",
            "Epoch 00041: loss did not improve\n",
            "Epoch 42/600\n",
            "48128/93587 [==============>...............] - ETA: 25s - loss: 0.1356"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 559us/step - loss: 0.1485\n",
            "\n",
            "Epoch 00042: loss did not improve\n",
            "Epoch 43/600\n",
            "49152/93587 [==============>...............] - ETA: 24s - loss: 0.1287"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1505\n",
            "\n",
            "Epoch 00043: loss did not improve\n",
            "Epoch 44/600\n",
            "49536/93587 [==============>...............] - ETA: 24s - loss: 0.1271"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 558us/step - loss: 0.1421\n",
            "\n",
            "Epoch 00044: loss did not improve\n",
            "Epoch 45/600\n",
            "49664/93587 [==============>...............] - ETA: 24s - loss: 0.1247"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 555us/step - loss: 0.1458\n",
            "\n",
            "Epoch 00045: loss did not improve\n",
            "Epoch 46/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1331"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 555us/step - loss: 0.1465\n",
            "\n",
            "Epoch 00046: loss did not improve\n",
            "Epoch 47/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1215"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.1453\n",
            "\n",
            "Epoch 00047: loss did not improve\n",
            "Epoch 48/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1387"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 555us/step - loss: 0.1596\n",
            "\n",
            "Epoch 00048: loss did not improve\n",
            "Epoch 49/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1280"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.1449\n",
            "\n",
            "Epoch 00049: loss did not improve\n",
            "Epoch 50/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1269"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.1423\n",
            "\n",
            "Epoch 00050: loss did not improve\n",
            "Epoch 51/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1213"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1403\n",
            "\n",
            "Epoch 00051: loss improved from 0.14134 to 0.14035, saving model to weights-improvement-51-0.1403.hdf5\n",
            "Epoch 52/600\n",
            "36736/93587 [==========>...................] - ETA: 31s - loss: 0.1276"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 555us/step - loss: 0.1430\n",
            "\n",
            "Epoch 00052: loss did not improve\n",
            "Epoch 53/600\n",
            "45056/93587 [=============>................] - ETA: 26s - loss: 0.1182"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 555us/step - loss: 0.1344\n",
            "\n",
            "Epoch 00053: loss improved from 0.14035 to 0.13444, saving model to weights-improvement-53-0.1344.hdf5\n",
            "Epoch 54/600\n",
            "35456/93587 [==========>...................] - ETA: 32s - loss: 0.1165"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 559us/step - loss: 0.1423\n",
            "\n",
            "Epoch 00054: loss did not improve\n",
            "Epoch 55/600\n",
            "44672/93587 [=============>................] - ETA: 27s - loss: 0.1285"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 558us/step - loss: 0.1493\n",
            "\n",
            "Epoch 00055: loss did not improve\n",
            "Epoch 56/600\n",
            "47744/93587 [==============>...............] - ETA: 25s - loss: 0.1271"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.1458\n",
            "\n",
            "Epoch 00056: loss did not improve\n",
            "Epoch 57/600\n",
            "49024/93587 [==============>...............] - ETA: 24s - loss: 0.1091"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 53s 562us/step - loss: 0.1301\n",
            "\n",
            "Epoch 00057: loss improved from 0.13444 to 0.13009, saving model to weights-improvement-57-0.1301.hdf5\n",
            "Epoch 58/600\n",
            "36480/93587 [==========>...................] - ETA: 31s - loss: 0.1182"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 561us/step - loss: 0.1385\n",
            "\n",
            "Epoch 00058: loss did not improve\n",
            "Epoch 59/600\n",
            "45056/93587 [=============>................] - ETA: 27s - loss: 0.1285"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 53s 565us/step - loss: 0.1426\n",
            "\n",
            "Epoch 00059: loss did not improve\n",
            "Epoch 60/600\n",
            "48128/93587 [==============>...............] - ETA: 25s - loss: 0.1229"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 560us/step - loss: 0.1392\n",
            "\n",
            "Epoch 00060: loss did not improve\n",
            "Epoch 61/600\n",
            "49152/93587 [==============>...............] - ETA: 24s - loss: 0.1243"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 559us/step - loss: 0.1399\n",
            "\n",
            "Epoch 00061: loss did not improve\n",
            "Epoch 62/600\n",
            "49536/93587 [==============>...............] - ETA: 24s - loss: 0.1105"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 559us/step - loss: 0.1296\n",
            "\n",
            "Epoch 00062: loss improved from 0.13009 to 0.12958, saving model to weights-improvement-62-0.1296.hdf5\n",
            "Epoch 63/600\n",
            "36608/93587 [==========>...................] - ETA: 31s - loss: 0.1092"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 559us/step - loss: 0.1279\n",
            "\n",
            "Epoch 00063: loss improved from 0.12958 to 0.12785, saving model to weights-improvement-63-0.1279.hdf5\n",
            "Epoch 64/600\n",
            "33280/93587 [=========>....................] - ETA: 33s - loss: 0.1267"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 560us/step - loss: 0.1423\n",
            "\n",
            "Epoch 00064: loss did not improve\n",
            "Epoch 65/600\n",
            "43904/93587 [=============>................] - ETA: 27s - loss: 0.1213"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 559us/step - loss: 0.1365\n",
            "\n",
            "Epoch 00065: loss did not improve\n",
            "Epoch 66/600\n",
            "47616/93587 [==============>...............] - ETA: 25s - loss: 0.1221"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 561us/step - loss: 0.1390\n",
            "\n",
            "Epoch 00066: loss did not improve\n",
            "Epoch 67/600\n",
            "49024/93587 [==============>...............] - ETA: 24s - loss: 0.1151"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 560us/step - loss: 0.1319\n",
            "\n",
            "Epoch 00067: loss did not improve\n",
            "Epoch 68/600\n",
            "49536/93587 [==============>...............] - ETA: 24s - loss: 0.1087"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 558us/step - loss: 0.1296\n",
            "\n",
            "Epoch 00068: loss did not improve\n",
            "Epoch 69/600\n",
            "49664/93587 [==============>...............] - ETA: 24s - loss: 0.1126"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 53s 564us/step - loss: 0.1304\n",
            "\n",
            "Epoch 00069: loss did not improve\n",
            "Epoch 70/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1328"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 560us/step - loss: 0.1407\n",
            "\n",
            "Epoch 00070: loss did not improve\n",
            "Epoch 71/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1171"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 560us/step - loss: 0.1337\n",
            "\n",
            "Epoch 00071: loss did not improve\n",
            "Epoch 72/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1067"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 560us/step - loss: 0.1208\n",
            "\n",
            "Epoch 00072: loss improved from 0.12785 to 0.12078, saving model to weights-improvement-72-0.1208.hdf5\n",
            "Epoch 73/600\n",
            "36736/93587 [==========>...................] - ETA: 31s - loss: 0.1113"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 557us/step - loss: 0.1327\n",
            "\n",
            "Epoch 00073: loss did not improve\n",
            "Epoch 74/600\n",
            "45056/93587 [=============>................] - ETA: 26s - loss: 0.1213"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 558us/step - loss: 0.1322\n",
            "\n",
            "Epoch 00074: loss did not improve\n",
            "Epoch 75/600\n",
            "48128/93587 [==============>...............] - ETA: 25s - loss: 0.1038"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 561us/step - loss: 0.1224\n",
            "\n",
            "Epoch 00075: loss did not improve\n",
            "Epoch 76/600\n",
            "49152/93587 [==============>...............] - ETA: 24s - loss: 0.1044"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 558us/step - loss: 0.1180\n",
            "\n",
            "Epoch 00076: loss improved from 0.12078 to 0.11796, saving model to weights-improvement-76-0.1180.hdf5\n",
            "Epoch 77/600\n",
            "36608/93587 [==========>...................] - ETA: 31s - loss: 0.1122"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 560us/step - loss: 0.1305\n",
            "\n",
            "Epoch 00077: loss did not improve\n",
            "Epoch 78/600\n",
            "45056/93587 [=============>................] - ETA: 27s - loss: 0.1356"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 559us/step - loss: 0.1428\n",
            "\n",
            "Epoch 00078: loss did not improve\n",
            "Epoch 79/600\n",
            "48128/93587 [==============>...............] - ETA: 25s - loss: 0.1067"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 560us/step - loss: 0.1162\n",
            "\n",
            "Epoch 00079: loss improved from 0.11796 to 0.11619, saving model to weights-improvement-79-0.1162.hdf5\n",
            "Epoch 80/600\n",
            "36224/93587 [==========>...................] - ETA: 32s - loss: 0.1049"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 559us/step - loss: 0.1256\n",
            "\n",
            "Epoch 00080: loss did not improve\n",
            "Epoch 81/600\n",
            "44928/93587 [=============>................] - ETA: 27s - loss: 0.1198"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 560us/step - loss: 0.1322\n",
            "\n",
            "Epoch 00081: loss did not improve\n",
            "Epoch 82/600\n",
            "48000/93587 [==============>...............] - ETA: 25s - loss: 0.1100"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 559us/step - loss: 0.1214\n",
            "\n",
            "Epoch 00082: loss did not improve\n",
            "Epoch 83/600\n",
            "49152/93587 [==============>...............] - ETA: 24s - loss: 0.1007"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 555us/step - loss: 0.1165\n",
            "\n",
            "Epoch 00083: loss did not improve\n",
            "Epoch 84/600\n",
            "49536/93587 [==============>...............] - ETA: 24s - loss: 0.1323"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1402\n",
            "\n",
            "Epoch 00084: loss did not improve\n",
            "Epoch 85/600\n",
            "49664/93587 [==============>...............] - ETA: 24s - loss: 0.1009"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 555us/step - loss: 0.1194\n",
            "\n",
            "Epoch 00085: loss did not improve\n",
            "Epoch 86/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.0983"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1131\n",
            "\n",
            "Epoch 00086: loss improved from 0.11619 to 0.11308, saving model to weights-improvement-86-0.1131.hdf5\n",
            "Epoch 87/600\n",
            "36736/93587 [==========>...................] - ETA: 31s - loss: 0.0985"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 557us/step - loss: 0.1169\n",
            "\n",
            "Epoch 00087: loss did not improve\n",
            "Epoch 88/600\n",
            "45056/93587 [=============>................] - ETA: 27s - loss: 0.1110"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 557us/step - loss: 0.1290\n",
            "\n",
            "Epoch 00088: loss did not improve\n",
            "Epoch 89/600\n",
            "48128/93587 [==============>...............] - ETA: 25s - loss: 0.1120"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1195\n",
            "\n",
            "Epoch 00089: loss did not improve\n",
            "Epoch 90/600\n",
            "49152/93587 [==============>...............] - ETA: 24s - loss: 0.0983"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1137\n",
            "\n",
            "Epoch 00090: loss did not improve\n",
            "Epoch 91/600\n",
            "49536/93587 [==============>...............] - ETA: 24s - loss: 0.1060"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.1246\n",
            "\n",
            "Epoch 00091: loss did not improve\n",
            "Epoch 92/600\n",
            "49664/93587 [==============>...............] - ETA: 24s - loss: 0.1172"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.1307\n",
            "\n",
            "Epoch 00092: loss did not improve\n",
            "Epoch 93/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.1079"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1162\n",
            "\n",
            "Epoch 00093: loss did not improve\n",
            "Epoch 94/600\n",
            "49792/93587 [==============>...............] - ETA: 24s - loss: 0.0932"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1077\n",
            "\n",
            "Epoch 00094: loss improved from 0.11308 to 0.10769, saving model to weights-improvement-94-0.1077.hdf5\n",
            "Epoch 95/600\n",
            "36736/93587 [==========>...................] - ETA: 31s - loss: 0.1212"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 555us/step - loss: 0.1323\n",
            "\n",
            "Epoch 00095: loss did not improve\n",
            "Epoch 96/600\n",
            "45056/93587 [=============>................] - ETA: 26s - loss: 0.0928"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.1047\n",
            "\n",
            "Epoch 00096: loss improved from 0.10769 to 0.10471, saving model to weights-improvement-96-0.1047.hdf5\n",
            "Epoch 97/600\n",
            "35456/93587 [==========>...................] - ETA: 32s - loss: 0.0872"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.1099\n",
            "\n",
            "Epoch 00097: loss did not improve\n",
            "Epoch 98/600\n",
            "44672/93587 [=============>................] - ETA: 27s - loss: 0.1114"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1326\n",
            "\n",
            "Epoch 00098: loss did not improve\n",
            "Epoch 99/600\n",
            "48000/93587 [==============>...............] - ETA: 25s - loss: 0.1229"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 555us/step - loss: 0.1284\n",
            "\n",
            "Epoch 00099: loss did not improve\n",
            "Epoch 100/600\n",
            "48768/93587 [==============>...............] - ETA: 24s - loss: 0.0890"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.0975\n",
            "\n",
            "Epoch 00100: loss improved from 0.10471 to 0.09754, saving model to weights-improvement-100-0.0975.hdf5\n",
            "Epoch 101/600\n",
            "36224/93587 [==========>...................] - ETA: 31s - loss: 0.0798"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 556us/step - loss: 0.1041\n",
            "\n",
            "Epoch 00101: loss did not improve\n",
            "Epoch 102/600\n",
            "44672/93587 [=============>................] - ETA: 27s - loss: 0.1158"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.1343\n",
            "\n",
            "Epoch 00102: loss did not improve\n",
            "Epoch 103/600\n",
            "47744/93587 [==============>...............] - ETA: 25s - loss: 0.1004"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 557us/step - loss: 0.1187\n",
            "\n",
            "Epoch 00103: loss did not improve\n",
            "Epoch 104/600\n",
            "48640/93587 [==============>...............] - ETA: 24s - loss: 0.1012"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.1153\n",
            "\n",
            "Epoch 00104: loss did not improve\n",
            "Epoch 105/600\n",
            "49152/93587 [==============>...............] - ETA: 24s - loss: 0.1206"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.1279\n",
            "\n",
            "Epoch 00105: loss did not improve\n",
            "Epoch 106/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.0991"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 558us/step - loss: 0.1073\n",
            "\n",
            "Epoch 00106: loss did not improve\n",
            "Epoch 107/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.0912"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 555us/step - loss: 0.1009\n",
            "\n",
            "Epoch 00107: loss did not improve\n",
            "Epoch 108/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.0974"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 557us/step - loss: 0.1118\n",
            "\n",
            "Epoch 00108: loss did not improve\n",
            "Epoch 109/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.1088"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 555us/step - loss: 0.1189\n",
            "\n",
            "Epoch 00109: loss did not improve\n",
            "Epoch 110/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.1056"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.1146\n",
            "\n",
            "Epoch 00110: loss did not improve\n",
            "Epoch 111/600\n",
            "49152/93587 [==============>...............] - ETA: 24s - loss: 0.0952"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.1067\n",
            "\n",
            "Epoch 00111: loss did not improve\n",
            "Epoch 112/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.0977"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.1137\n",
            "\n",
            "Epoch 00112: loss did not improve\n",
            "Epoch 113/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.1032"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 552us/step - loss: 0.1171\n",
            "\n",
            "Epoch 00113: loss did not improve\n",
            "Epoch 114/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.1120"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.1213\n",
            "\n",
            "Epoch 00114: loss did not improve\n",
            "Epoch 115/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.0982"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 552us/step - loss: 0.1090\n",
            "\n",
            "Epoch 00115: loss did not improve\n",
            "Epoch 116/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.0863"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.0994\n",
            "\n",
            "Epoch 00116: loss did not improve\n",
            "Epoch 117/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.0820"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 550us/step - loss: 0.1056\n",
            "\n",
            "Epoch 00117: loss did not improve\n",
            "Epoch 118/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.1094"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 552us/step - loss: 0.1253\n",
            "\n",
            "Epoch 00118: loss did not improve\n",
            "Epoch 119/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.1064"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 552us/step - loss: 0.1143\n",
            "\n",
            "Epoch 00119: loss did not improve\n",
            "Epoch 120/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.0836"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 51s 550us/step - loss: 0.0941\n",
            "\n",
            "Epoch 00120: loss improved from 0.09754 to 0.09414, saving model to weights-improvement-120-0.0941.hdf5\n",
            "Epoch 121/600\n",
            "36352/93587 [==========>...................] - ETA: 31s - loss: 0.0856"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.1036\n",
            "\n",
            "Epoch 00121: loss did not improve\n",
            "Epoch 122/600\n",
            "44672/93587 [=============>................] - ETA: 27s - loss: 0.0980"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.1097\n",
            "\n",
            "Epoch 00122: loss did not improve\n",
            "Epoch 123/600\n",
            "47744/93587 [==============>...............] - ETA: 25s - loss: 0.0983"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 552us/step - loss: 0.1102\n",
            "\n",
            "Epoch 00123: loss did not improve\n",
            "Epoch 124/600\n",
            "48768/93587 [==============>...............] - ETA: 24s - loss: 0.1061"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 551us/step - loss: 0.1164\n",
            "\n",
            "Epoch 00124: loss did not improve\n",
            "Epoch 125/600\n",
            "49152/93587 [==============>...............] - ETA: 24s - loss: 0.0879"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 552us/step - loss: 0.1033\n",
            "\n",
            "Epoch 00125: loss did not improve\n",
            "Epoch 126/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.0860"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.0992\n",
            "\n",
            "Epoch 00126: loss did not improve\n",
            "Epoch 127/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.0929"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.1082\n",
            "\n",
            "Epoch 00127: loss did not improve\n",
            "Epoch 128/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.1067"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.1167\n",
            "\n",
            "Epoch 00128: loss did not improve\n",
            "Epoch 129/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.0896"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 554us/step - loss: 0.1041\n",
            "\n",
            "Epoch 00129: loss did not improve\n",
            "Epoch 130/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.0787"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.0912\n",
            "\n",
            "Epoch 00130: loss improved from 0.09414 to 0.09117, saving model to weights-improvement-130-0.0912.hdf5\n",
            "Epoch 131/600\n",
            "36352/93587 [==========>...................] - ETA: 31s - loss: 0.0790"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 552us/step - loss: 0.0934\n",
            "\n",
            "Epoch 00131: loss did not improve\n",
            "Epoch 132/600\n",
            "44672/93587 [=============>................] - ETA: 26s - loss: 0.0971"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 551us/step - loss: 0.1171\n",
            "\n",
            "Epoch 00132: loss did not improve\n",
            "Epoch 133/600\n",
            "47744/93587 [==============>...............] - ETA: 25s - loss: 0.1155"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.1229\n",
            "\n",
            "Epoch 00133: loss did not improve\n",
            "Epoch 134/600\n",
            "48640/93587 [==============>...............] - ETA: 24s - loss: 0.0931"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 553us/step - loss: 0.1003\n",
            "\n",
            "Epoch 00134: loss did not improve\n",
            "Epoch 135/600\n",
            "49152/93587 [==============>...............] - ETA: 25s - loss: 0.0761"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 53s 566us/step - loss: 0.0870\n",
            "\n",
            "Epoch 00135: loss improved from 0.09117 to 0.08703, saving model to weights-improvement-135-0.0870.hdf5\n",
            "Epoch 136/600\n",
            "36224/93587 [==========>...................] - ETA: 32s - loss: 0.0788"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 53s 564us/step - loss: 0.0988\n",
            "\n",
            "Epoch 00136: loss did not improve\n",
            "Epoch 137/600\n",
            "44672/93587 [=============>................] - ETA: 27s - loss: 0.0966"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 53s 566us/step - loss: 0.1120\n",
            "\n",
            "Epoch 00137: loss did not improve\n",
            "Epoch 138/600\n",
            "47744/93587 [==============>...............] - ETA: 25s - loss: 0.1008"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 53s 566us/step - loss: 0.1098\n",
            "\n",
            "Epoch 00138: loss did not improve\n",
            "Epoch 139/600\n",
            "48768/93587 [==============>...............] - ETA: 25s - loss: 0.0767"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 53s 562us/step - loss: 0.0907\n",
            "\n",
            "Epoch 00139: loss did not improve\n",
            "Epoch 140/600\n",
            "49152/93587 [==============>...............] - ETA: 24s - loss: 0.0801"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 555us/step - loss: 0.0984\n",
            "\n",
            "Epoch 00140: loss did not improve\n",
            "Epoch 141/600\n",
            "49280/93587 [==============>...............] - ETA: 24s - loss: 0.1087"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "93587/93587 [==============================] - 52s 552us/step - loss: 0.1151\n",
            "\n",
            "Epoch 00141: loss did not improve\n",
            "Epoch 142/600\n",
            "33792/93587 [=========>....................] - ETA: 32s - loss: 0.0824"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-21c1d330b694>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           callbacks=[checkpoint])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "C80STSOfXhwO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "fe0ce92c-fffd-4031-d6c8-46a012e04c77",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520576731819,
          "user_tz": 480,
          "elapsed": 887,
          "user": {
            "displayName": "Qingzhuo Aw Young",
            "photoUrl": "//lh5.googleusercontent.com/-KgAiD_zBKV8/AAAAAAAAAAI/AAAAAAAAEKY/z2XK7TaGpXM/s50-c-k-no/photo.jpg",
            "userId": "100798512376314782861"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab\t\t\t\t     weights-improvement-26-0.5547.hdf5\r\n",
            "example.txt\t\t\t     weights-improvement-27-0.5253.hdf5\r\n",
            "first\t\t\t\t     weights-improvement-28-0.5036.hdf5\r\n",
            "shakespeare.txt\t\t\t     weights-improvement-29-0.4801.hdf5\r\n",
            "weights-improvement-01-0.1083.hdf5   weights-improvement-30-0.4562.hdf5\r\n",
            "weights-improvement-01-0.2480.hdf5   weights-improvement-31-0.4357.hdf5\r\n",
            "weights-improvement-01-2.4741.hdf5   weights-improvement-32-0.4259.hdf5\r\n",
            "weights-improvement-02-0.0610.hdf5   weights-improvement-33-0.4045.hdf5\r\n",
            "weights-improvement-02-0.1709.hdf5   weights-improvement-34-0.3924.hdf5\r\n",
            "weights-improvement-02-2.0126.hdf5   weights-improvement-35-0.1495.hdf5\r\n",
            "weights-improvement-03-0.0344.hdf5   weights-improvement-35-0.3824.hdf5\r\n",
            "weights-improvement-03-0.1545.hdf5   weights-improvement-36-0.3712.hdf5\r\n",
            "weights-improvement-03-1.8378.hdf5   weights-improvement-37-0.3560.hdf5\r\n",
            "weights-improvement-04-0.0191.hdf5   weights-improvement-38-0.3478.hdf5\r\n",
            "weights-improvement-04-1.7308.hdf5   weights-improvement-39-0.1413.hdf5\r\n",
            "weights-improvement-05-0.0130.hdf5   weights-improvement-39-0.3271.hdf5\r\n",
            "weights-improvement-05-1.6496.hdf5   weights-improvement-40-0.3219.hdf5\r\n",
            "weights-improvement-06-0.0100.hdf5   weights-improvement-41-0.3202.hdf5\r\n",
            "weights-improvement-06-1.5821.hdf5   weights-improvement-42-0.3063.hdf5\r\n",
            "weights-improvement-07-0.0083.hdf5   weights-improvement-43-0.2942.hdf5\r\n",
            "weights-improvement-07-1.5212.hdf5   weights-improvement-44-0.2905.hdf5\r\n",
            "weights-improvement-08-1.4620.hdf5   weights-improvement-45-0.2867.hdf5\r\n",
            "weights-improvement-09-1.4019.hdf5   weights-improvement-46-0.2794.hdf5\r\n",
            "weights-improvement-100-0.0975.hdf5  weights-improvement-47-0.2735.hdf5\r\n",
            "weights-improvement-10-1.3429.hdf5   weights-improvement-48-0.2693.hdf5\r\n",
            "weights-improvement-11-1.2827.hdf5   weights-improvement-49-0.2567.hdf5\r\n",
            "weights-improvement-120-0.0941.hdf5  weights-improvement-51-0.1403.hdf5\r\n",
            "weights-improvement-12-1.2211.hdf5   weights-improvement-51-0.2546.hdf5\r\n",
            "weights-improvement-130-0.0912.hdf5  weights-improvement-52-0.2483.hdf5\r\n",
            "weights-improvement-13-1.1588.hdf5   weights-improvement-53-0.1344.hdf5\r\n",
            "weights-improvement-135-0.0870.hdf5  weights-improvement-54-0.2440.hdf5\r\n",
            "weights-improvement-14-1.0963.hdf5   weights-improvement-55-0.2306.hdf5\r\n",
            "weights-improvement-15-1.0364.hdf5   weights-improvement-57-0.1301.hdf5\r\n",
            "weights-improvement-16-0.9776.hdf5   weights-improvement-57-0.2304.hdf5\r\n",
            "weights-improvement-17-0.9207.hdf5   weights-improvement-58-0.2236.hdf5\r\n",
            "weights-improvement-18-0.8680.hdf5   weights-improvement-62-0.1296.hdf5\r\n",
            "weights-improvement-19-0.8192.hdf5   weights-improvement-63-0.1279.hdf5\r\n",
            "weights-improvement-20-0.7700.hdf5   weights-improvement-72-0.1208.hdf5\r\n",
            "weights-improvement-21-0.7282.hdf5   weights-improvement-76-0.1180.hdf5\r\n",
            "weights-improvement-22-0.6866.hdf5   weights-improvement-79-0.1162.hdf5\r\n",
            "weights-improvement-23-0.6495.hdf5   weights-improvement-86-0.1131.hdf5\r\n",
            "weights-improvement-24-0.6134.hdf5   weights-improvement-94-0.1077.hdf5\r\n",
            "weights-improvement-25-0.5813.hdf5   weights-improvement-96-0.1047.hdf5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6p-IGrRAb9B3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('weights-improvement-135-0.0870.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6kl90QHncHCj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 31
            },
            {
              "item_id": 63
            },
            {
              "item_id": 95
            },
            {
              "item_id": 129
            },
            {
              "item_id": 146
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "d40a249e-29ca-4fe5-b306-ed24be733cb0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520577001399,
          "user_tz": 480,
          "elapsed": 36075,
          "user": {
            "displayName": "Qingzhuo Aw Young",
            "photoUrl": "//lh5.googleusercontent.com/-KgAiD_zBKV8/AAAAAAAAAAI/AAAAAAAAEKY/z2XK7TaGpXM/s50-c-k-no/photo.jpg",
            "userId": "100798512376314782861"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import sys\n",
        "start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "    print('----- diversity:', diversity)\n",
        "\n",
        "    generated = ''\n",
        "    sentence = 'thy glass will show thee how thy beautie'#text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "\n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds, diversity)\n",
        "        next_char = indices_char[next_index]\n",
        "\n",
        "        generated += next_char\n",
        "        sentence = sentence[1:] + next_char\n",
        "\n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"thy glass will show thee how thy beautie\"\n",
            "thy glass will show thee how thy beauties wear,\n",
            "thy dial how thy precious minutes waste,\n",
            "these vacant leaves thy mind's imprint will bear,\n",
            "and of this book, this learning mads of slow,\n",
            "to sincuse to the earthanct of my love,\n",
            "thy self thy self thy e-didelich praise.\n",
            "like as the wadds but of things to rise mine eye,\n",
            "and all my soul, and all my every part;\n",
            "and for this sin "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "the child of him and kee)\n",
            "leath trively for a kind of beary canse,\n",
            "\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"thy glass will show thee how thy beautie\"\n",
            "thy glass will show thee how thy beauties wear,\n",
            "thy dial how thy precious minutes waste,\n",
            "these vacant leaves thy mind's imprint will bear,\n",
            "and make the larged bud your monnory,\n",
            "or if they cruelioned when i spence.\n",
            "but sweets in thy fair perpessed that died.\n",
            "but wherefore do die, my self alone hearts\n",
            "that love is as your bo"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "unty doth deceive.\n",
            "and that thou tencels in all you a wood.\n",
            "i heavy seear thou art full-fleater,\n",
            "i sable grace varin\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"thy glass will show thee how thy beautie\"\n",
            "thy glass will show thee how thy beauties wear,\n",
            "thy dial how thy precious minutes waste,\n",
            "but now to gone, for another, shap was tomb.\n",
            "thy beauty styen's are part in warth grows\n",
            "loads woild have toon might in yet the share,\n",
            "and thy strangely gave no more be cheal,\n",
            "to let not when you for "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "him in ithan your sweet,\n",
            "finding that buding have i fasted time.\n",
            "or may the eye hath flething, and i seem,\n",
            "till now all-ummant with her of a spory,\n",
            "sama\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"thy glass will show thee how thy beautie\"\n",
            "thy glass will show thee how thy beauties wear,\n",
            "thy dial hy admeate, art to make that burse,\n",
            "but yet thou mayst in me thou mayst can see,\n",
            "so now i have your longer' bads ang ermed,\n",
            "and to thy please him what i thy pars, feelfurned,\n",
            "or ance fine my love and thing"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "s of lears,\n",
            "thrin shows my mistress vexceled, and i brevided\n",
            "whon'ersmorn pergeauty not to his, and in\n",
            "mine works wenk of your disgrace, and cheeks new rade spirith:\n",
            "and such a c\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}